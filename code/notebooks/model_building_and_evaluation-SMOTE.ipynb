{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999505e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:21:58.706709Z",
     "start_time": "2024-03-25T09:21:58.506889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import all necessary Python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b3c310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:22:07.050624Z",
     "start_time": "2024-03-25T09:22:06.935732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading from the Training and testing data\n",
    "\n",
    "X_train = pd.read_csv('../data/train_data/X_train_res.csv')\n",
    "y_train = pd.read_csv('../data/train_data/y_train_res.csv')\n",
    "\n",
    "X_test = pd.read_csv('../data/test_data/X_test.csv')\n",
    "y_test = pd.read_csv('../data/test_data/y_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be911431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:22:07.887090Z",
     "start_time": "2024-03-25T09:22:07.882933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selected Models for the evaluation\n",
    "\n",
    "models = [\n",
    "    (LogisticRegression(), {'model__C': [0.1, 1, 10]}),\n",
    "    (DecisionTreeClassifier(), {'model__max_depth': [3, 5, 7]}),\n",
    "    (RandomForestClassifier(), {'model__n_estimators': [50, 100, 200]}),\n",
    "    (KNeighborsClassifier(), {'model__n_neighbors': [3, 5, 7]}),\n",
    "    (GaussianNB(), {}),  # Naive Bayes doesn't have hyperparameters\n",
    "    (XGBClassifier(use_label_encoder=False, eval_metric='logloss'), {'model__n_estimators': [50, 100, 200], 'model__max_depth': [3, 5, 7]}),\n",
    "    (AdaBoostClassifier(), {'model__n_estimators': [50, 100, 200], 'model__learning_rate': [0.01, 0.1, 1]})\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29250c0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:22:23.553998Z",
     "start_time": "2024-03-25T09:22:23.538852Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_and_evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    model_names = []\n",
    "    accuracies = []\n",
    "    f1_scores = []\n",
    "    base_path = '../models_smote_approach'\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    fprs, tprs, roc_aucs, model_labels = [], [], [], []\n",
    "    for model, params in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        print(f\"Building and Evaluation of the model: {model_name}\")\n",
    "        model_path = os.path.join(base_path, model_name)\n",
    "        os.makedirs(model_path, exist_ok=True)\n",
    "        \n",
    "        pipe = Pipeline([('model', model)])\n",
    "        grid_search = GridSearchCV(pipe, params, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Save the model\n",
    "        joblib.dump(best_model, os.path.join(model_path, f'{model_name}.joblib'))\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "        model_names.append(model_name)\n",
    "        \n",
    "        # F1 Score\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # Classification Report\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        with open(os.path.join(model_path, 'classification_report.txt'), 'w') as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.title(f\"Confusion Matrix for {model_name}\")\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.savefig(os.path.join(model_path, 'confusion_matrix.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # ROC Curve\n",
    "        if len(np.unique(y_test)) == 2:  # Check if binary classification\n",
    "            y_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], 'k--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title(f'ROC Curve for {model_name}')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.savefig(os.path.join(model_path, 'roc_curve.png'))\n",
    "            plt.close()\n",
    "            # Store FPR, TPR, and AUC for later plotting\n",
    "            fprs.append(fpr)\n",
    "            tprs.append(tpr)\n",
    "            roc_aucs.append(roc_auc)\n",
    "            model_labels.append(model_name)\n",
    "\n",
    "        if hasattr(best_model.named_steps['model'], 'feature_importances_'):\n",
    "            importances = best_model.named_steps['model'].feature_importances_\n",
    "\n",
    "            # Sort the feature importances in descending order\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "\n",
    "            feature_names = np.array(X_train.columns)\n",
    "\n",
    "            # Plotting the feature importances\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.title(\"Feature Importances\")\n",
    "            plt.bar(range(X_train.shape[1]), importances[indices], color=\"steelblue\", align=\"center\")\n",
    "            plt.xticks(range(X_train.shape[1]), [feature_names[i] for i in indices], rotation=90)\n",
    "            plt.xlim([-1, X_train.shape[1]])\n",
    "            plt.xlabel(\"Feature\")\n",
    "            plt.ylabel(\"Importance\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(model_path, 'feature_importance.png'))\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(f\"The model in the pipeline does not support feature importances.\")\n",
    "         \n",
    "    # Plotting model comparison for Accuracy\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=model_names, y=accuracies)\n",
    "    plt.title('Model Comparison - Accuracy')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(os.path.join(base_path, 'model_accuracy_comparison.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Assuming you have calculated and appended F1 scores in f1_scores list\n",
    "    # Plotting model comparison for F1 Score\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=model_names, y=f1_scores)\n",
    "    plt.title('Model Comparison - F1 Score')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(os.path.join(base_path, 'model_f1_score_comparison.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for fpr, tpr, roc_auc, label in zip(fprs, tprs, roc_aucs, model_labels):\n",
    "        plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Chance (AUC = 0.50)')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves Comparison')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(os.path.join(base_path, 'roc_curves_comparison.png'))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571d8426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-25T09:26:29.796455Z",
     "start_time": "2024-03-25T09:22:25.308755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building and Evaluation of the model: LogisticRegression\n",
      "The model in the pipeline does not support feature importances.\n",
      "Building and Evaluation of the model: DecisionTreeClassifier\n",
      "Building and Evaluation of the model: RandomForestClassifier\n",
      "Building and Evaluation of the model: KNeighborsClassifier\n",
      "The model in the pipeline does not support feature importances.\n",
      "Building and Evaluation of the model: GaussianNB\n",
      "The model in the pipeline does not support feature importances.\n",
      "Building and Evaluation of the model: XGBClassifier\n",
      "Building and Evaluation of the model: AdaBoostClassifier\n"
     ]
    }
   ],
   "source": [
    "# Example usage (assuming you have your models list, and X_train, X_test, y_train, y_test ready)\n",
    "build_and_evaluate_models(models, X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589ec2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
